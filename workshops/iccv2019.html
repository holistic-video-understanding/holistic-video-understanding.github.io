<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>First International Workshop on Holistic Video Understanding</title>

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="../css/bootstrap.min.css" type="text/css">

    <!-- Custom Fonts -->
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="../font-awesome/css/font-awesome.min.css" type="text/css">

    <!-- Plugin CSS -->
    <link rel="stylesheet" href="../css/animate.min.css" type="text/css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="../css/main.css" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>


<body id="page-top">
  <nav id="mainNav" class="navbar navbar-default navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand page-scroll" href="#page-top">HVU</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
		
		<li>
                    <a class="page-scroll" href="#about">About</a>
                </li>
                <li>
                    <a class="page-scroll" href="#speakers">Speakers</a>
                </li>
                <li>
                    <a class="page-scroll" href="#organizers">Organizers</a>
                </li>
                <li>
                    <a class="page-scroll" href="#contact">Contact</a>
                </li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container-fluid -->
</nav>

  <header style="background-image:url(img/header-seoul-lights-1920x1080.jpg)">
    <div class="header-content" style="color:white; background-color: rgba(0, 0, 0, 0.4);">
        <div class="header-content-inner">
            <h1>First International Workshop on Large Scale Holistic Video Understanding</h1>
            <hr>
            <h2">In Conjunction with ICCV 2019, Seoul, Korea</h2>
            <!--<a href="#about" class="btn btn-primary btn-xl page-scroll">Find Out More</a>-->
        </div>
    </div>
</header>

  <section class="bg-primary" id="about">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 text-center">
                <h2 class="section-heading">Large Scale Holistic Video Understanding</h2>
                <hr class="light">
                <p class="text-faded" align="justify">In the last years, we have seen a tremendous progress in the capabilities of computer systems to classify video clips taken from the Internet or to analyze human actions in videos. There are lots of works in video recognition field focusing on specific video understanding tasks, such as, action recognition, scene understanding, etc. There have been great achievements in such tasks, however, there has not been enough attention toward the holistic video understanding task as a problem to be tackled. Current systems are expert in some specific fields of the general video understanding problem. However, for real world applications, such as, analyzing multiple concepts of a video for video search engines and media monitoring systems or providing an appropriate definition of the surrounding environment of an humanoid robot, a combination of current state-of-the-art methods should be used. 

				Therefore, in this workshop we intend to introduce the holistic video understanding as a new challenge for the video understanding efforts. This challenge focuses on the recognition of scenes, objects, actions, attributes, and events in the real world user generated videos. To be able to address such tasks, we also introduce our new dataset named Holistic Video Understanding~(HVU dataset) that is organized hierarchically in a semantic taxonomy of holistic video understanding. Almost all of real-wold conditioned video datasets are targeting human action or sport recognition. So our new dataset can help the vision community and bring more attention to bring more interesting solutions for holistic video understanding.
				The workshop is tailored on bringing together ideas around  multi-label and multi-task recognition of different semantic concepts in the real world videos. And the research efforts can be tried on our new dataset. </p>
                <!--<a href="#" class="btn btn-default btn-xl">Coming Soon</a>-->
            </div>
        </div>
    </div>
  </section>
<section class="no-padding" id="speakers">
    
      <div class="container-fluid">
  	  	<div class="container">
	        <div class="row">
	            <div class="col-lg-12 text-center">
	                <h2 class="section-heading">Speakers</h2>
	                <hr class="primary">
	            </div>
	        </div>
    	</div>
        <div class="row no-gutter">
            <div class="col-md-3" style="align-content: right;">
                <a href="https://ai.google/research/people/RahulSukthankar" target="_blank" class="portfolio-box">
                    <img src="img/portfolio/RahulSukthankar.png" class="img-responsive" alt="">
		    		<br><p>Rahul  Sukthankar</p>
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-category text-faded">
                                Rahul  Sukthankar
                            </div>
                            <div class="project-name">
                                is a Principal Scientist/Director at Google AI Perception leading research efforts in computer vision, machine learning and robotics. He is also an adjunct research professor at the Robotics Institute at Carnegie Mellon and courtesy faculty at the University of Central Florida.
                            </div>
                        </div>
                    </div>
                </a>
            </div>
            <div class="col-md-3">
                <a href="http://www.cs.utexas.edu/users/grauman/" target="_blank" class="portfolio-box">
                    <img src="img/portfolio/KristenGrauman.png" class="img-responsive" alt="">
                    <br><p>Kristen Grauman</p>
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-category text-faded">
                                Kristen Grauman
                            </div>
                            <div class="project-name">
                                is a Professor in the Department of Computer Science at the University of Texas at Austin, where she leads the UT-Austin Computer Vision Group.  She was elected to the Academy of Distinguished Teachers at UT Austin in 2017.  She received my Ph.D. from MIT in the Computer Science and Artificial Intelligence Laboratory in 2006.  
                            </div>
                        </div>
                    </div>
                </a>
            </div>
		   <div class="col-md-3">
	                <a href="http://www.cs.columbia.edu/~vondrick/" target="_blank" class="portfolio-box">
	                    <img src="img/portfolio/CarlVondrick.png" class="img-responsive" alt="">
	                    <br><p>Carl Vondrick</p>
	                    <div class="portfolio-box-caption">
	                        <div class="portfolio-box-caption-content">
	                            <div class="project-category text-faded">
	                                Carl Vondrick
	                            </div>
	                            <div class="project-name">
	                                is an Assistant Professor in the Department of Computer Science at the Columbia University. His group focuses on computer vision and machine learning.
	                            </div>
	                        </div>
	                    </div>
	                </a>
	        </div>
	        <div class="col-md-3">
	                <a href="https://research.fb.com/people/paluri-manohar/" target="_blank" class="portfolio-box">
	                    <img src="img/portfolio/MonoharPaluri.png" class="img-responsive" alt="">
	                    <br><p>Manohar Paluri</p>
	                    <div class="portfolio-box-caption">
	                        <div class="portfolio-box-caption-content">
	                            <div class="project-category text-faded">
	                                Manohar Paluri
	                            </div>
	                            <div class="project-name">
	                                is a director in Facebook AI research and manages thecomputer vision efforts.  He is passionate about pushing the state of the art in computer  vision  to  help  billions  of  people  to  connect  in  new  and  meaningful ways.
	                            </div>
	                        </div>
	                    </div>
	                </a>
	        </div>
        </div>
        </div>
    </div>
</section>
<aside class="bg-gray" >
      <div class="container text-center">
          <div class="call-to-action">
              <h2>Organizers</h2>
          </div>
      </div>
      <section class="no-padding" id="organizers">
    
      <div class="container-fluid">
      		<div class="row no-gutter">
	            <div class="col-md-4" >
	                <a href="http://mohsenfayyaz89.github.io" taget="_blank" class="portfolio-box">
	                    <img src="img/portfolio/MohsenFayyaz.png" class="img-responsive" alt="">
			    		<br><p>Mohsen Fayyaz</p>
	                    <div class="portfolio-box-caption">
	                        <div class="portfolio-box-caption-content">
	                            <div class="project-category text-faded">
	                                Mohsen Fayyaz
	                            </div>
	                            <div class="project-name">
	                                is a PhD candidate at the University of Bonn.
	                            </div>
	                        </div>
	                    </div>
	                </a>
	            </div>
	            <div class="col-md-4">
	                <a href="https://www.esat.kuleuven.be/psi/members/00098021" target="_blank" class="portfolio-box">
	                    <img src="img/portfolio/AliDiba.png" class="img-responsive" alt="">
	                    <br><p>Ali Diba</p>
	                    <div class="portfolio-box-caption">
	                        <div class="portfolio-box-caption-content">
	                            <div class="project-category text-faded">
	                                Ali Diba
	                            </div>
	                            <div class="project-name">
	                                is a PhD candidate at the KU-Leuven University.
	                            </div>
	                        </div>
	                    </div>
	                </a>
	            </div>
			   <div class="col-md-4">
		                <a href="http://vivoutlaw.github.io/" target="_blank" class="portfolio-box">
		                    <img src="img/portfolio/VivekSharma.png" class="img-responsive" alt="">
		                    <br><p>Vivek Sharma</p>
		                    <div class="portfolio-box-caption">
		                        <div class="portfolio-box-caption-content">
		                            <div class="project-category text-faded">
		                                Vivek Sharma
		                            </div>
		                            <div class="project-name">
		                                is a PhD candidate at the Karlsruhe Institute of Technology.
		                            </div>
		                        </div>
		                    </div>
		                </a>
		        </div>
		        
        	</div>
        </div>
        <section class="no-padding" id="speakers">
    
      <div class="container-fluid">
  	  	
        <div class="row no-gutter">
            <div class="col-md-3">
                <a href="https://www.vision.ee.ethz.ch/en/members/get_member.cgi?id=1" target="_blank" class="portfolio-box">
                    <img src="img/portfolio/LucVanGool.png" class="img-responsive" alt="">
		    		<br><p>Luc Van Gool</p>
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-category text-faded">
                                Luc Van Gool
                            </div>
                            <div class="project-name">
                                is a full professor for computer vision at both the KULeuven  and  the  ETH  Zurich. He leads computer vision research groups at both places and has authored more than 400 papers in leading journals and conferences. His research includes 3D acquisition and modeling, object and object class recognition, tracking, and gesture recognition.
                            </div>
                        </div>
                    </div>
                </a>
            </div>
            <div class="col-md-3">
                <a href="http://gall.cv-uni-bonn.de/" target="_blank" class="portfolio-box">
                    <img src="img/portfolio/JuergenGall.png" class="img-responsive" alt="">
                    <br><p>Juergen Gall</p>
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-category text-faded">
                                Juergen Gall
                            </div>
                            <div class="project-name">
                                is professor and head of the Computer Vision Group at the University of Bonn. He is further spokesperson of the DFG funded research unit "Anticipating Human Behavior" at the University of Bonn since 2017. He co-organized several workshops and tutorials on solving real-world vision problems with RGB-D cameras and on affordances for scene analysis in conjunction with CVPR/ICCV/ECCV/RSS.  
                            </div>
                        </div>
                    </div>
                </a>
            </div>
		   <div class="col-md-3">
	                <a href="https://cvhci.anthropomatik.kit.edu/people_596.php" target="_blank" class="portfolio-box">
	                    <img src="img/portfolio/RainerStiefelhagen.png" class="img-responsive" alt="">
	                    <br><p>Rainer Stiefelhagen</p>
	                    <div class="portfolio-box-caption">
	                        <div class="portfolio-box-caption-content">
	                            <div class="project-category text-faded">
	                                Rainer Stiefelhagen
	                            </div>
	                            <div class="project-name">
	                                is a full professor at the Karlsruhe Institute of Technology (KIT) where he directs the Computer Vision for Human-Computer Interaction  Lab  at  the  Institute  for  Anthropomatics  and  Robotics  as  well  as KITâ€™s  Study  Center  for  Visually  Impaired  Students. His research interests include image and video understanding and in particular the perception of people in image and video, including their gestures, actions, identities, etc. 
	                            </div>
	                        </div>
	                    </div>
	                </a>
	        </div>
	        <div class="col-md-3">
	                <a href="https://research.fb.com/people/paluri-manohar/" target="_blank" class="portfolio-box">
	                    <img src="img/portfolio/MonoharPaluri.png" class="img-responsive" alt="">
	                    <br><p>Manohar Paluri</p>
	                    <div class="portfolio-box-caption">
	                        <div class="portfolio-box-caption-content">
	                            <div class="project-category text-faded">
	                                Manohar Paluri
	                            </div>
	                            <div class="project-name">
	                                is a director in Facebook AI research and manages thecomputer vision efforts.  He is passionate about pushing the state of the art in computer  vision  to  help  billions  of  people  to  connect  in  new  and  meaningful ways.
	                            </div>
	                        </div>
	                    </div>
	                </a>
	        </div>
        </div>
        </div>
    </div>
</section>
    </div>
</section>
</aside>

  <!-- jQuery -->
<script src="../js/jquery.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="../js/bootstrap.min.js"></script>

<!-- Plugin JavaScript -->
<script src="../js/jquery.easing.min.js"></script>
<script src="../js/jquery.fittext.js"></script>
<script src="../js/wow.min.js"></script>

<!-- Custom Theme JavaScript -->
<script src="../js/creative.js"></script>

</body>

</html>

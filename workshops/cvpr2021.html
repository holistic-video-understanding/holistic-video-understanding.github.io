<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Second International Workshop on Holistic Video Understanding</title>
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">
    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="../css/bootstrap.min.css" type="text/css">

    <!-- Custom Fonts -->
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="../fontawesome/css/all.css" type="text/css">

    <!-- Plugin CSS -->
    <link rel="stylesheet" href="../css/animate.min.css" type="text/css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="../css/main.css" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
    <script type="text/javascript">
        window.heap=window.heap||[],heap.load=function(e,t){window.heap.appid=e,window.heap.config=t=t||{};var r=t.forceSSL||"https:"===document.location.protocol,a=document.createElement("script");a.type="text/javascript",a.async=!0,a.src=(r?"https:":"http:")+"//cdn.heapanalytics.com/js/heap-"+e+".js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(a,n);for(var o=function(e){return function(){heap.push([e].concat(Array.prototype.slice.call(arguments,0)))}},p=["addEventProperties","addUserProperties","clearEventProperties","identify","resetIdentity","removeEventProperty","setEventProperties","track","unsetEventProperty"],c=0;c<p.length;c++)heap[p[c]]=o(p[c])};
          heap.load("1625312160");
    </script>

</head>


<body id="page-top">
  <nav id="mainNav" class="navbar navbar-default navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand page-scroll" href="#page-top">HVU</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
		
				<li>
                    <a class="page-scroll" href="#about">About</a>
                </li>
                <li>
                    <a class="page-scroll" href="#speakers">Speakers</a>
                </li>
                <li>
                    <a class="page-scroll" href="#awards">Awards</a>
                </li>
                <li>
                    <a class="page-scroll" href="#program">Workshop Program</a>
                </li>
                <li>
                    <a class="page-scroll" href="#call-for-paper">Call for Paper</a>
                </li>
                <li>
                    <a class="page-scroll" href="#pc">Program Commitee</a>
                </li>
                <li>
                    <a class="page-scroll" href="#organizers">Organizers</a>
                </li>
                <li>
                    <a class="page-scroll" href="#sponsors">Sponsors</a>
                </li>
                <li>
                    <a class="page-scroll" href="#contact">Contact</a>
                </li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container-fluid -->
</nav>

  <header style="background-image:url('http://cvpr2021.thecvf.com/sites/default/files/2020-12/CVPR_2021_Home%20Page.jpg')">
    <div class="header-content" style="color:white; background-color: rgba(0, 0, 0, 0.4);">
        <div class="header-content-inner">
        	
            <h1>Second International Workshop on Large Scale Holistic Video Understanding</h1>
            <hr>
            <h2">In Conjunction with CVPR 2021,</h2>
            <!--<a href="#about" class="btn btn-primary btn-xl page-scroll">Find Out More</a>-->
            <a href="" target="_blank">
            	<img src="" class="img-logo" alt="">
            </a>
        </div>
    </div>
</header>

<section class="text-dark" id="about">
    <div class="container">
    	<div class="row" style="padding-bottom: 50px">
    		<div class="col-md-6">
    			<p>Holistic Video Understanding is a joint project of the KU Leuven, University of Bonn, KIT, ETH, and the <a href="../index.html#team" target="_blank">HVU team</a>.</p>
    		</div>
    		<div class="col-md-6">
    			<div class="row">
		    		<div class="col-md-4 text-center">
		    			<img src="../img/portfolio/KULeuven.png" class="img-logo" alt="">
		    		</div>
		    		<div class="col-md-4 text-center">
		    			<img src="../img/portfolio/Bonn.png" class="img-logo" alt="">
		    		</div>
		    		<div class="col-md-4 text-center">
		    			<img src="../img/portfolio/KIT.svg" class="img-logo" alt="">
		    		</div>
		    	</div>
		    	<div class="row">
		    		<div class="col-md-4 text-center">
		    			<img src="../img/portfolio/ETH.png" class="img-logo" alt="">
		    		</div>
		    	</div>
    		</div>
    	</div>
        <div class="row">
            <!--<div class="col-lg-8 col-lg-offset-2 text-center">-->
            <div class="col-md-6 text-center">
                <h2 class="section-heading">ABOUT THE WORKSHOP</h2>
                <hr class="light">
                <p class="text-dark" align="justify">In the last years, we have seen tremendous progress in the capabilities of computer systems to classify video clips taken from the Internet or to analyze human actions in videos. There are lots of works in video recognition field focusing on specific video understanding tasks, such as action recognition, scene understanding, etc. There have been great achievements in such tasks, however, there has not been enough attention toward the holistic video understanding task as a problem to be tackled. Current systems are expert in some specific fields of the general video understanding problem. However, for real-world applications, such as, analyzing multiple concepts of a video for video search engines and media monitoring systems or providing an appropriate definition of the surrounding environment of a humanoid robot, a combination of current state-of-the-art methods should be used. Therefore, in this workshop, we intend to introduce the holistic video understanding as a new challenge for the video understanding efforts. This challenge focuses on the recognition of scenes, objects, actions, attributes, and events in the real world user-generated videos. To be able to address such tasks, we also introduce our new dataset named Holistic Video Understanding~(HVU dataset) that is organized hierarchically in a semantic taxonomy of holistic video understanding. Almost all of the real-world conditioned video datasets are targeting human action or sport recognition. So our new dataset can help the vision community and bring more attention to bring more interesting solutions for holistic video understanding. The workshop is tailored to bringing together ideas around multi-label and multi-task recognition of different semantic concepts in the real world videos. And the research efforts can be tried on our new dataset.</p>
                <!--<a href="#" class="btn btn-default btn-xl">Coming Soon</a>-->
            </div>
            <div class="col-md-6 text-center">
                <h2 class="section-heading">WHAT IS OUR GOAL?</h2>
                <hr class="light">
                <p class="text-dark" align="justify">The main objective of the workshop is to establish a video benchmark integrating joint recognition of all the semantic concepts,  as a single class label per task is often not sufficient to describe the holistic content of a video. The planned panel discussion with world’s leading experts on this problem will be a fruitful input and source of ideas for all participants. Further, we invite the community to help to extend the HVU dataset that will spur research in video understanding as a comprehensive, multi-faceted problem. We as organizers expect to receive valuable feedback from users and from the community on how to improve the benchmark. <!--A few potential issues for the discussion are:--></p>
                <h2 class="section-heading">TOPICS</h2>
                <hr class="light">
                <ul class="text-dark" style="font-size: 20px" align="left">
                <li>Large scale video understanding</li>
                <li>Multi-Modal learning from videos</li>
                <li>Multi concept recognition from videos</li>
				<li>Multi task deep neural networks for videos</li>
				<li>Learning holistic representation from videos</li>
				<li>Weakly supervised learning from web videos</li>
				<li>Object, scene and event recognition from videos</li>
				<li>Unsupervised video visual representation learning</li>
				<li>Unsupervised and self-­supervised learning with videos</li>
                </ul>
                <!--<a href="#" class="btn btn-default btn-xl">Coming Soon</a>-->
            </div>
        </div>
    </div>
</section>

<section class="bg-gray" id="speakers">
    
      <div class="container">
        
        <div class="row">
            <div class="col-lg-12 text-center">
                <h2 class="section-heading">SPEAKERS</h2>
                <hr class="primary">
            </div>
        </div>
        
        
        <div class="row no-gutter">
            <div class="col-md-4" style="align-content: right;" id="S1">
                <a href="https://thoth.inrialpes.fr/~schmid/" target="_blank" class="portfolio-box">
                    <img src="img/portfolio/CordeliaSchmid.png" class="img-responsive" alt="">
                    <br><p>Cordelia Schmid</p>
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-category text-faded">
                                Cordelia Schmid
                            </div>
                            <div class="project-name">
                                Research Director<br>INRIA/Google Research
                            </div>
                        </div>
                    </div>
                </a>
            </div>
            <div class="col-md-4" id="S2">
                <a href="https://www.linkedin.com/in/jo%C3%A3o-carreira-56238a7/?originalSubdomain=uk" target="_blank" class="portfolio-box">
                    <img src="img/portfolio/JoaoCarreira.png" class="img-responsive" alt="">
                    <br><p>Joao Carreira</p>
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-category text-faded">
                                Joao Carreira
                            </div>
                            <div class="project-name">
                                Staff Research Scientist at Google DeepMind
                            </div>
                        </div>
                    </div>
                </a>
            </div>
            <div class="col-md-4" style="align-content: right;" id="S8">
                <a href="http://www.cs.columbia.edu/~vondrick/" target="_blank" class="portfolio-box">
                    <img src="img/portfolio/CarlVondrick.png" class="img-responsive" alt="">
                    <br><p>Carl Vondrick</p>
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-category text-faded">
                                Carl Vondrick
                            </div>
                            <div class="project-name">
                                 Assistant Professor, Columbia University
                            </div>
                        </div>
                    </div>
                </a>
            </div>
            <div class="col-md-4" id="S4">
                    <a href="http://people.cs.bris.ac.uk/~damen/" target="_blank" class="portfolio-box">
                        <img src="img/portfolio/DimaDamen.png" class="img-responsive" alt="">
                        <br><p>Dima Damen</p>
                        <div class="portfolio-box-caption">
                            <div class="portfolio-box-caption-content">
                                <div class="project-category text-faded">
                                    Dima Damen
                                </div>
                                <div class="project-name">
                                    Associate Professor at the Department of Computer Science, Visual Information Laboratory, University of Bristol
                                </div>
                            </div>
                        </div>
                    </a>
            </div>
            <div class="col-md-4" id="S4">
                    <a href="https://www.cs.utoronto.ca/~fidler/" target="_blank" class="portfolio-box">
                        <img src="img/portfolio/SanjaFidler.png" class="img-responsive" alt="">
                        <br><p>Sanja Fidler</p>
                        <div class="portfolio-box-caption">
                            <div class="portfolio-box-caption-content">
                                <div class="project-category text-faded">
                                    Sanja Fidler
                                </div>
                                <div class="project-name">
                                    Associate Professor, University of Toronto <br> Director of AI, NVIDIA
                                </div>
                            </div>
                        </div>
                    </a>
            </div>
            <div class="col-md-4" id="S4">
                    <a href="https://www.cs.utexas.edu/users/grauman/" target="_blank" class="portfolio-box">
                        <img src="img/portfolio/KristenGrauman.png" class="img-responsive" alt="">
                        <br><p>Kristen Grauman</p>
                        <div class="portfolio-box-caption">
                            <div class="portfolio-box-caption-content">
                                <div class="project-category text-faded">
                                    Kristen Grauman
                                </div>
                                <div class="project-name">
                                    Professor in the Department of Computer Science at the University of Texas at Austin <br> Head of the UT-Austin Computer Vision Group
                                </div>
                            </div>
                        </div>
                    </a>
            </div>
        </div>
    
        </div>
    </div>
</section>
<!--
<section class="" id="awards">
    <div class="container">
        
        <div class="row">
            <div class="col-lg-12 text-center">

                <h2 class="section-heading">AWARDS</h2>
                <i class="fas fa-award fa-4x wow bounceIn" data-wow-delay=".1s"></i>
                <hr class="primary">
            </div>
        </div>
        <div class="row">
            <div class="col-md-6 text-center" style="display: flex; justify-content: center; font-size: 18px">
                <div>
                    <h3 class="section-heading">Best Paper Award</h3>
                    <hr class="primary">
                    <div style="justify-content: left;">
                        <b >TBA</b>
                    </div>
                </div>
            </div>
            <div class="col-md-6 text-center" style="display: flex; justify-content: center; font-size: 18px">
                <div>
                    <h3 class="section-heading">Best Poster Award</h3>
                    <hr class="primary">
                    <b>TBA</b>
                </div>
            </div>
        </div>
        <div class="row">
            <div class="col-lg-12 text-center" style="display: flex; justify-content: center; font-size: 16px; padding-top: 40px">
                TBA
            </div>
        </div>
    </div>
    
</section>-->

<section class="" id="program">
    
 <div class="container">
        
        <div class="row">
            <div class="col-lg-12 text-center">
                <h2 class="section-heading">WORKSHOP PROGRAM</h2>
                <hr class="primary">
                <div class="text-dark" style="font-size: 19px">
                    June 25th, Full day; Zoom and Youtube Link: TBA <br><b></b></a><br>
                </div>
            </div>
        </div>
	
        
        <div class="row no-gutter">
            <div class="col-lg col-lg-offset-0  align-center" style="display: flex; justify-content: center; font-size: 18px">
                <table>
                  <tbody>
                    

                    <tr>
                        <td style="min-width: 70px"><b>ET | CET</b></td>
                        <td colspan="0" style="min-width: 170px"><b>&nbsp;&nbsp; Description</b></td>
                        <td colspan="0" style=""><b>&nbsp;&nbsp; Speaker/Paper ID</b></td>
                    </tr>
                    <tr>
                        <td>11:00 | 17:00</td>
                        <td>&nbsp;&nbsp; Opening remark</td>
                        <td></td>
                    </tr>
                    <tr>
                        <td>11:10 | 17:10</td>
                        <td>&nbsp;&nbsp; Invited Speaker 1: </td>
                        <td colspan="0"><a class="page-scroll" href="#S2">&nbsp;&nbsp; Joao Carreira</a></td>
                    </tr>
                    <tr>
                        <td>12:00 | 18:00</td>
                        <td>&nbsp;&nbsp; Invited Speaker 2:</td>
                        <td><a class="page-scroll" href="#S1">&nbsp;&nbsp; Cordelia Schmid</a></td>
                    </tr>
                    <tr>
                        <td>12:50 | 18:50</td>
                        <td>&nbsp;&nbsp; Invited Speaker 3:</td>
                        <td colspan="2"><a class="page-scroll" href="#S3">&nbsp;&nbsp; Dima Damen</a></td>
                    </tr>
                    <tr>
                        <td>13:40 | 19:40</td>
                        <td>&nbsp;&nbsp; Oral Session 1</td>
                        <td colspan="2"><a class="page-scroll" href="#orals1">&nbsp;&nbsp; 1, 2, 3, 4, 5, 6</a></td>
                    </tr>
                    <tr>
                        <td>14:40 | 20:40</td>
                        <td>&nbsp;&nbsp; Break</td>
                        <td ></td>
                    </tr>
                    <tr>
                        <td>15:10 | 21:10</td>
                        <td>&nbsp;&nbsp; Oral Session 2</td>
                        <td colspan="2"><a class="page-scroll" href="#orals2">&nbsp;&nbsp; 7, 8, 9, 10, 11, 12</a></td>
                    </tr>
                    <tr>
                        <td>16:10 | 22:10</td>
                        <td>&nbsp;&nbsp; Invited Speaker 4: </td>
                        <td colspan="0"><a class="page-scroll" href="#S8">&nbsp;&nbsp; Carl Vondrick</a></td>
                    </tr>
                    <tr>
                        <td>17:00 | 23:00</td>
                        <td>&nbsp;&nbsp; Invited Speaker 5: </td>
                        <td colspan="0"><a class="page-scroll" href="#S5">&nbsp;&nbsp; Sanja Fidler</a></td>
                    </tr>
                    <tr>
                        <td>17:50 | 23:50</td>
                        <td>&nbsp;&nbsp; Invited Speaker 6: </td>
                        <td colspan="0"><a class="page-scroll" href="#S6">&nbsp;&nbsp; Kristen Grauman</a></td>
                    </tr>
                    <tr>
                        <td>18:40 | 00:40</td>
                        <td>&nbsp;&nbsp; Conclusion</td>
                        <td></td>
                    </tr>
                    </tbody>
                </table>
            </div>
        </div>
        <div class="row" id="orals">
           <div class="col-lg col-lg-offset-0 text-center" style="padding-left: 15px; padding-right: 15px; padding-top: 30px">
                <h2 class="section-heading">Oral Papers</h2>
                <hr class="primary">
		<ol class="text-dark text-left" aligh="justify" style="font-size: 19px"> 
                    <li><b>IntegralAction: Pose-driven Feature Integration for Robust Human Action Recognition in Videos</b>; Gyeongsik Moon, Heeseung Kwon, Kyoung Mu Lee, Minsu Cho<br></li>
                    <li><b>Rethinking Training Data for Mitigating Representation Biases in Action Recognition</b>; Kensho Hara, Yuchi Ishikawa, Hirokatsu Kataoka<br></li>
                    <li><b>MDMMT: Multidomain Multimodal Transformer for Video Retrieval</b>; Maksim Dzabraev, Maksim Kalashnikov, Stepan A Komkov, Aleksandr Petiushko<br></li>
                    <li><b>SAIL-VOS 3D: A Synthetic Dataset and Baselines for Object Detection and 3D Mesh Reconstruction from Video Data</b>; Yuan-Ting Hu, Jiahong Wang, Raymond A Yeh, Alexander Schwing<br></li>
                    <li><b>ObjectGraphs: Using Objects and a Graph Convolutional Network for the Bottom-up Recognition and Explanation of Events in Video</b>; Nikolaos Gkalelis, Andreas Goulas, Damianos Galanopoulos, Vasileios Mezaris<br></li>
                    <li><b>CoCon: Cooperative-Contrastive Learning</b>; Nishant Rai, Ehsan Adeli, Kuan-Hui Lee, Adrien Gaidon, Juan Carlos Niebles<br></li>
		    <li><b> Learning to Segment Actions from Visual and Language Instructions via Differentiable Weak Sequence Alignment</b>; Yuhan Shen, Lu Wang, Ehsan Elhamifar<br></li>
                    <li><b>Training vision transformers for image retrieval</b>; Alaaeldin El-Nouby, Natalia Neverova, Ivan Laptev, Hervé Jégou<br></li>
                    <li><b>Unidentified Video Objects: A Benchmark for Dense, Open-World Segmentation</b>; Weiyao Wang, Matt Feiszli, Heng Wang, Du Tran<br></li>
                    <li><b>Learning Video Representations from Textual Web Supervision</b>; Jonathan C. Stroud, David A. Ross, Chen Sun, Jia Deng, Rahul Sukthankar, Cordelia Schmid<br></li>
                    <li><b>Parameter Efficient Multimodal Transformers for Video Representation Learning</b>; Sangho Lee, Youngjae Yu, Gunhee Kim, Thomas Breuel, Jan Kautz, Yale Song<br></li>
                    <li><b>Just Ask: Learning to Answer Questions from Millions of Narrated Videos</b>; Antoine Yang, Antoine Miech, Josef Sivic, Ivan Laptev, Cordelia Schmid<br></li>
		</ol>
            </div> 
        </div>

	
							      
    </div>

</section>

<section class="bg-gray" id="call-for-paper">
	<div class="container" >
		<div class="row">
            <!--<div class="col-lg-8 col-lg-offset-2 text-center">-->
            <div class="col-lg col-lg-offset-0 text-center" style="padding-left: 15px; padding-right: 15px" >
                <h2 class="section-heading">CALL FOR PAPER</h2>
                <hr class="primary">
                <p class="text-dark" align="justify">Prospective authors will be invited to submit a regular paper of previously unpublished work (CVPR paper format) or an extended abstract of a published work. The review process will be double blind. All the submissions will be peer-reviewed by the international program committee. Accepted papers will be presented as posters or contributed talks and will be considered non-archival and published via the Open Access versions, provided by the Computer Vision Foundation. Accepted extended abstracts will be presented at the poster session.</p>
                <!--<a href="#" class="btn btn-default btn-xl">Coming Soon</a>-->
            </div>
        </div>
        
        <div class="row align-center">
        	<div class="col-md-3 text-center">
        		<div class="service-box">
        			<a class="page-scroll" href="#submission">
	        			<i class="fas fa-paper-plane fa-4x wow bounceIn" data-wow-delay=".1s"></i>
	        			<h4>Paper Submission Starts*</h4>
	                                <h4><strike>February 20</strike></h4>
	        		</a>
        		</div>
        	</div>
        	<div class="col-md-3 text-center">
        		<div class="service-box">
        			<a href="https://cmt3.research.microsoft.com/HVU2021" target="_blank">
	        			<i class="fas fa-flag fa-4x wow bounceIn" data-wow-delay=".1s"></i>
	        			<h4>Paper Submission Deadline</h4>
					<h4><strike>March 31</strike></h4>
        			</a>
        		</div>
        	</div>
        	<div class="col-md-3 text-center">
        		<div class="service-box">
                    <a href="https://cmt3.research.microsoft.com/HVU2021" target="_blank">
        			 <i class="fas fa-check fa-4x wow bounceIn" data-wow-delay=".1s"></i>
        			 <h4>Notification of Acceptance</h4>
        			 <h4><strike>April 14</strike></h4>
                    </a>
        		</div>
        	</div>
        	<div class="col-md-3 text-center">
        		<div class="service-box">
                    <a href="https://cmt3.research.microsoft.com/HVU2019" target="_blank">
        			 <i class="fas fa-camera fa-4x wow bounceIn" data-wow-delay=".1s"></i>
        			 <h4>Camera Ready Submission</h4>
				 <h4><strike>April 18</strike></h4>
                    </a>
        		</div>
        	</div>
        </div>
        <div class="row align-center">
        
        	<div class="col-lg-8 col-lg-offset-2 text-center">
            <div class="col-lg col-lg-offset-0 text-center" style="padding-left: 15px; padding-right: 15px; padding-top: 35px" >
        		<div class="service-box">
        			<i class="fas fa-users fa-4x wow bounceIn" data-wow-delay=".1s"></i>
        			<h4>Workshop</h4>
        			<h4>June 25th</h4>
        		</div>
        	</div>
        	</div>
        </div>
        
        <!--</div>-->

        <!--
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 text-center">
                s
            <div class="col-lg col-lg-offset-0 text-center" style="padding-left: 15px; padding-right: 15px; padding-top: 35px" >
                <h2 class="section-heading"></h2>
                <i class="fas fa-award fa-4x wow bounceIn" data-wow-delay=".1s"></i>
                <h4 class="text-dark" align="justify-center">Best paper and best poster will receive prizes</h4>
            	
            </div>
        </div>
    -	-->
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 text-center">
            <div class="col-lg col-lg-offset-0 text-center" style="padding-left: 15px; padding-right: 15px; padding-top: 35px" >
                <h2 class="section-heading"></h2>
                <a href="https://github.com/holistic-video-understanding/HVU-Dataset" target="_blank">
                	<i class="fas fa-database fa-4x wow bounceIn" data-wow-delay=".1s"></i>
                	<h4 align="justify-center">Get the DataSet!</h4>
			<h4 class="text-dark" align="justify-center">The authors are encouraged to use our dataset in their submission, but it is not mandatory.</h4>
						  
            	</a>
            </div>
        	</div>
        </div>
        
        <div class="row">
            <div class="col-lg col-lg-offset-0 text-center" style="padding-left: 15px; padding-right: 15px; padding-top: 35px" id="submission" >
                <h2 class="section-heading">Submission</h2>
                <hr class="primary">
                <p class="text-dark" align="justify">
                	*You can submit papers in two different formats:
                	<ol class="text-dark" align="justify">
	                	<li>We will accept papers that have not been published elsewhere or have been recently published elsewhere including CVPR 2021. Accepted papers will appear in CVPR proceedings. For submissions of papers, we will follow the <b>Double Blind</b> review process, in that authors do not know the names of the reviewers of their papers, and reviewers do not know the names of the authors. The authors must follow the CVPR 2021 submission policy. Papers are limited to eight pages, including figures and tables, in the CVPR style. Additional pages containing only cited references are allowed. Please refer to the CVPR 2021 website for more information. Papers that are not properly anonymized, or do not use the template, or have more than eight pages (excluding references) will be rejected without review. The deadline for paper submission is <b>March 31st</b>. Notification to the authors by <b>April 14th</b>. The accepted papers must follow the CVPR 2021 camera-ready format as per the instructions are given here but limit your paper to 4-8 pages excluding references.</li>
	                	
						<li>For submissions of papers that have been published or accepted for publication in a recent venue, we will follow the <b>Single Blind</b> review process, in that authors do not know the names of the reviewers of their papers, but reviewers do know the names of the authors. Authors MUST indicate, in the footnote section on the first page of their submission, which venue their papers have been published or will be published. For example, if the paper will appear at CVPR 2021, the submission should include a footnote on the first page showing "To appear at 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition".</li>
						
						<!--<li>Authors can also submit a maximum of 4-8 pages (excluding references) which will be peer-reviewed. We will follow the <b>Single Blind</b> review process. However, they will not be included in the proceedings. Accepted papers will be presented as posters or contributed talks. Authors of accepted papers will be asked to post their submissions on arXiv. The workshop website will provide links to the accepted papers on arXiv. Accepted papers will be considered non-archival, and may be submitted elsewhere (modified or not). Therefore, the deadline for paper submission is <b>March 31st</b>. Notification to the authors by <b>April 14th</b>.</li>-->
					</ol>
					All papers must be formatted using the CVPR template style, which can be obtained at <a href="http://cvpr2021.thecvf.com/sites/default/files/2020-09/cvpr2021AuthorKit_2.zip">CVPR style</a>.</p>
                <a href="https://cmt3.research.microsoft.com/HVU2021" target="_blank" class="btn btn-default btn-xl">Submit Your Work</a>
            </div>
        </div> 
	</div>
</section>


<section class="" id="pc">
    <div class="container">
    	<div class="row text-center">
    		<h2 class="section-heading">Program Commitee</h2>
    		<hr class="primary">
    	</div>
        <div class="row">
            <!--<div class="col-lg-8 col-lg-offset-2 text-center">-->
            <div class="col-md-6 text-center">
                <ul class="text-dark" style="font-size: 20px" align="left">
                
                
                <li>Abhishek	Aich	(University of California, Riverside)</li>
                <li>AJ	Piergiovanni	(Google / Indiana University)</li>
                <li>Akash	Gupta	(University of California, Riverside)</li>
                <li>Alejandro	Pardo	(KAUST)</li>
		<li>Amogh	Gupta	(Columbia University)</li>
                <li>Ananda	Chowdhury	(Jadavpur University)</li>
                <li>Anna	Kukleva	(MPII)</li>
                <li>Bing	Li	(KAUST)</li>
                <li>Boxiao	Pan	(Stanford University)</li>
		<li>Boyuan	Chen	(Columbia University)</li>
		<li>Bruno	Korbar	(Facebook)</li>
		<li>Chengzhi	Mao	(Columbia University)</li>
		<li>Evangelos	Kazakos	(University of Bristol)</li>
		<li>Graham	Taylor	(University of Guelph)</li>
		<li>Hazel	Doughty	(University of Amsterdam)</li>
		<li>Jinwoo	Choi	(Kyung Hee University)</li>
		<li>Karttikeya	Mangalam	(UC Berkeley)</li>
		<li>Khoi-Nguyen	Mac	(UIUC)</li>
		<li>Hilde	Kuehne	(IBM)</li>
		<li>Jinwoo	Choi	(Kyung Hee University)</li>
		<li>Karttikeya	Mangalam	(UC Berkeley)</li>
		<li>Khoi-Nguyen	Mac	(UIUC)</li>
				
				
                </ul>
                <!--<a href="#" class="btn btn-default btn-xl">Coming Soon</a>-->
            </div>
            <div class="col-md-6 text-center">
                <ul class="text-dark" style="font-size: 20px" align="left">
                
		
		<li>Michael	Wray	(University of Bristol)</li>
		<li>Mingmin	Zhao	(MIT)</li>
		<li>Mohammad	Sabokrou	(Institute for Research in Fundamental Sciences (IPM))</li>
		<li>Mohammadreza	Zolfaghari	(University of Freiburg)</li>
		<li>Nadine	Behrmann	(Bosch Center for Artificial Intelligence)</li>
		<li>Nikita	Araslanov	(TU Darmstadt)</li>
		<li>Pascal	Mettes	(University of Amsterdam)</li>
		<li>Rameswar	Panda	(MIT-IBM Watson AI Lab, IBM Research)</li>
		<li>Ruohan	Gao	(Stanford University)</li>
		<li>Sachit	Menon	(Duke University)</li>
		<li>Shyamal	Buch	(Stanford University)</li>
		<li>Silvio	Giancola	(KAUST)</li>
		<li>Tao	Hu	(University of Amsterdam)</li>
		<li>Tengda	Han	(University of Oxford)</li>
		<li>Weidi	Xie	(University of Oxford)</li>
		<li>Yang	Liu	(University of Oxford)</li>
		<li>Yingcheng	Liu	(MIT)</li>
		<li>Yunhua	Zhang	(University of Amsterdam)</li>
		<li>Zhicheng	Yan	(Facebook AI)</li>
		
                </ul>
            
                <!--<a href="#" class="btn btn-default btn-xl">Coming Soon</a>-->
            </div>
        </div>
    </div>
</section>

<section class="bg-gray" id="organizers">
      <div class="container text-center">
      <div class="row">
          <div class="call-to-action">
              <h2>ORGANIZERS</h2>
              <hr class="primary">
          </div>
      </div>
      		<div class="row no-gutter">
      			<div class="col-md-4" >
	                <a href="http://mohsenfayyaz89.github.io" target="_blank" class="portfolio-box">
	                    <img src="img/portfolio/MohsenFayyaz.png" class="img-responsive" alt="">
			    		<br><p>Mohsen Fayyaz</p>
	                    <div class="portfolio-box-caption">
	                        <div class="portfolio-box-caption-content">
	                            <div class="project-category text-faded">
	                                Mohsen Fayyaz
	                            </div>
	                            <div class="project-name">
	                                PhD candidate at the University of Bonn
	                            </div>
	                        </div>
	                    </div>
	                </a>
	            </div>
                <div class="col-md-4">
		                <a href="http://vivoutlaw.github.io/" target="_blank" class="portfolio-box">
		                    <img src="img/portfolio/VivekSharma.png" class="img-responsive" alt="">
		                    <br><p>Vivek Sharma</p>
		                    <div class="portfolio-box-caption">
		                        <div class="portfolio-box-caption-content">
		                            <div class="project-category text-faded">
		                                Vivek Sharma
		                            </div>
		                            <div class="project-name">
		                                
		                            </div>
		                        </div>
		                    </div>
		                </a>
		        </div>
	            
	            <div class="col-md-4">
	                <a href="https://www.esat.kuleuven.be/psi/members/00098021" target="_blank" class="portfolio-box">
	                    <img src="img/portfolio/AliDiba.png" class="img-responsive" alt="">
	                    <br><p>Ali Diba</p>
	                    <div class="portfolio-box-caption">
	                        <div class="portfolio-box-caption-content">
	                            <div class="project-category text-faded">
	                                Ali Diba
	                            </div>
	                            <div class="project-name">
	                                PhD candidate at the KU-Leuven University
	                            </div>
	                        </div>
	                    </div>
	                </a>
	            </div>
		        
        	</div>
        
        	
        <div class="row no-gutter">
            <div class="col-md-4">
                <a href="https://www.vision.ee.ethz.ch/en/members/get_member.cgi?id=1" target="_blank" class="portfolio-box">
                    <img src="img/portfolio/LucVanGool.png" class="img-responsive" alt="">
		    		<br><p>Luc Van Gool</p>
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-category text-faded">
                                Luc Van Gool
                            </div>
                            <div class="project-name">
                                Full Professor for Computer Vision at both the KULeuven  and  the  ETH  Zurich
                            </div>
                        </div>
                    </div>
                </a>
            </div>
            <div class="col-md-4">
                <a href="http://gall.cv-uni-bonn.de/" target="_blank" class="portfolio-box">
                    <img src="img/portfolio/JuergenGall.png" class="img-responsive" alt="">
                    <br><p>Juergen Gall</p>
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-category text-faded">
                                Juergen Gall
                            </div>
                            <div class="project-name">
                                Full Professor and Head of the Computer Vision Group at the University of Bonn
                            </div>
                        </div>
                    </div>
                </a>
            </div>
            <div class="col-md-4" >
                    <a href="https://web.stanford.edu/~eadeli/" target="_blank" class="portfolio-box">
                        <img src="img/portfolio/EhsanAdeli.png" class="img-responsive" alt="">
                        <br><p>Ehsan Adeli</p>
                        <div class="portfolio-box-caption">
                            <div class="portfolio-box-caption-content">
                                <div class="project-category text-faded">
                                    Ehsan Adeli
                                </div>
                                <div class="project-name">
                                    Faculty at Computational Neurosience Lab and affiliated with Stanford AI Lab and Stanford Vision Lab
                                </div>
                            </div>
                        </div>
                    </a>
            </div>
            <div class="col-md-4">
                    <a href="http://www.cs.toronto.edu/~dross/" target="_blank" class="portfolio-box">
                        <img src="img/portfolio/DavidRoss.png" class="img-responsive" alt="">
                        <br><p>David Ross</p>
                        <div class="portfolio-box-caption">
                            <div class="portfolio-box-caption-content">
                                <div class="project-category text-faded">
                                    David Ross
                                </div>
                                <div class="project-name">
                                    Head of the Visual Dynamics research group, Google AI Perception
                                </div>
                            </div>
                        </div>
                    </a>
            </div>
		   <div class="col-md-4">
	                <a href="https://cvhci.anthropomatik.kit.edu/people_596.php" target="_blank" class="portfolio-box">
	                    <img src="img/portfolio/RainerStiefelhagen.png" class="img-responsive" alt="">
	                    <br><p>Rainer Stiefelhagen</p>
	                    <div class="portfolio-box-caption">
	                        <div class="portfolio-box-caption-content">
	                            <div class="project-category text-faded">
	                                Rainer Stiefelhagen
	                            </div>
	                            <div class="project-name">
	                                Full Professor at the Karlsruhe Institute of Technology (KIT)
	                            </div>
	                        </div>
	                    </div>
	                </a>
	        </div>
	        <div class="col-md-4">
	                <a href="https://research.fb.com/people/paluri-manohar/" target="_blank" class="portfolio-box">
	                    <img src="img/portfolio/ManoharPaluri.png" class="img-responsive" alt="">
	                    <br><p>Manohar Paluri</p>
	                    <div class="portfolio-box-caption">
	                        <div class="portfolio-box-caption-content">
	                            <div class="project-category text-faded">
	                                Manohar Paluri
	                            </div>
	                            <div class="project-name">
	                                Director in Facebook AI Research
	                            </div>
	                        </div>
	                    </div>
	                </a>
	        </div>
        </div>
        
    </div>


</section>
							     
 <!--
<section class="" id="sponsors">
	<div class="container">
		<div class="row">
          <div class="col-lg-8 col-lg-offset-2 text-center">
              <h2>SPONSORS</h2>
              <hr class="primary">
          </div>
      	</div>
        TBA
        
		<div class="row">
			<div class="col-md-4 col-lg-offset-0 text-center">
	            
	                <img src="img/portfolio/FacebookAI.png" class="img-responsive" alt="" style="padding-top: 20px">
	                <p style="padding-top: 10px"><br>Facebook AI Research</p>
	            
	        </div>
	        <div class="col-md-4 col-lg-offset-0 text-center">
                
                    <img src="img/portfolio/Apple_Logo_Black.png" class="img-responsive" alt="" style="width: 17%; height: 17%; padding-top: 0px">
                    <p style="padding-top: 25px">Apple</p>
                
            </div>
            <div class="col-md-4 text-center">
	            
		            <img src="img/portfolio/sensifai.svg" class="img-responsive" alt="" style="padding-top: 25px">
		            <p style="padding-top: 10px"><br>Sensifai</p>
	            
	        </div>
            
	        
	        <div class="col-md-3 text-center">
	            <a href="http://www.apple.com" target="_blank" >
	            	<i class="fab fa-apple fa-4x" style="color: black"></i>
		            <img src="img/portfolio/apple.png" class="img-responsive" alt="" style="padding-top: 0px">
		            <p><br>Apple</p>
	            </a>
	        </div>
	        <div class="col-md-3 text-center">
	            <a href="https://research.samsung.com/aicenter" target="_blank">
		            <img src="img/portfolio/samsung.png" class="img-responsive" alt="" style="padding-top: 10px">
		            <p style="padding-top: 2px"><br>Samsung</p>
	            </a>
	        </div>
		</div>
	</div>
</section>
-->

<section class="bg-gray" id="contact">
    <div class="container">
        <div class="row">

            <div class="col-lg-8 col-lg-offset-2 text-center">
                <h2 class="section-heading">CONTACT</h2>
                <hr class="primary">
                
            </div>
        </div>
        <div class="row">
	        <div class="col-lg-2 col-lg-offset-2 text-center">
	            <a href="https://twitter.com/LSHVU" target="_blank">
	                <i class="fab fa-twitter fa-3x wow bounceIn" data-wow-delay=".1s"></i>
	                <p>@LSHVU</p>
	            </a>
	        </div>
	        <div class="col-lg-2 col-lg-offset-1 text-center">
	            <a href="mailto:fayyaz@iai.uni-bonn.de">
	                <i class="fas fa-envelope fa-3x wow bounceIn" data-wow-delay=".1s"></i>
                	<p>fayyaz@iai.uni-bonn.de</p>
	            </a>
	        </div>
	        <div class="col-lg-2 col-lg-offset-1 text-center">
	            <a href="https://github.com/holistic-video-understanding" target="_blank">
	            <i class="fab fa-github fa-3x wow bounceIn" data-wow-delay=".1s"></i>
	                <p>holistic-video-understanding</p>
	            </a>
	        </div>

    	</div>
    </div>
</section>
  <!-- jQuery -->
<script src="../js/jquery.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="../js/bootstrap.min.js"></script>

<!-- Plugin JavaScript -->
<script src="../js/jquery.easing.min.js"></script>
<script src="../js/jquery.fittext.js"></script>
<script src="../js/wow.min.js"></script>

<!-- Custom Theme JavaScript -->
<script src="../js/creative.js"></script>

</body>

</html>

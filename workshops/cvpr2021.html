<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Second International Workshop on Holistic Video Understanding</title>
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">
    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="../css/bootstrap.min.css" type="text/css">

    <!-- Custom Fonts -->
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="../fontawesome/css/all.css" type="text/css">

    <!-- Plugin CSS -->
    <link rel="stylesheet" href="../css/animate.min.css" type="text/css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="../css/main.css" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
    <script type="text/javascript">
        window.heap=window.heap||[],heap.load=function(e,t){window.heap.appid=e,window.heap.config=t=t||{};var r=t.forceSSL||"https:"===document.location.protocol,a=document.createElement("script");a.type="text/javascript",a.async=!0,a.src=(r?"https:":"http:")+"//cdn.heapanalytics.com/js/heap-"+e+".js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(a,n);for(var o=function(e){return function(){heap.push([e].concat(Array.prototype.slice.call(arguments,0)))}},p=["addEventProperties","addUserProperties","clearEventProperties","identify","resetIdentity","removeEventProperty","setEventProperties","track","unsetEventProperty"],c=0;c<p.length;c++)heap[p[c]]=o(p[c])};
          heap.load("1625312160");
    </script>

</head>


<body id="page-top">
  <nav id="mainNav" class="navbar navbar-default navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand page-scroll" href="#page-top">HVU</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
		
				<li>
                    <a class="page-scroll" href="#about">About</a>
                </li>
                <li>
                    <a class="page-scroll" href="#speakers">Speakers</a>
                </li>
                <li>
                    <a class="page-scroll" href="#awards">Awards</a>
                </li>
                <li>
                    <a class="page-scroll" href="#program">Workshop Program</a>
                </li>
                <li>
                    <a class="page-scroll" href="#call-for-paper">Call for Paper</a>
                </li>
                <li>
                    <a class="page-scroll" href="#pc">Program Commitee</a>
                </li>
                <li>
                    <a class="page-scroll" href="#organizers">Organizers</a>
                </li>
                <li>
                    <a class="page-scroll" href="#sponsors">Sponsors</a>
                </li>
                <li>
                    <a class="page-scroll" href="#contact">Contact</a>
                </li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container-fluid -->
</nav>

  <header style="background-image:url('http://cvpr2021.thecvf.com/sites/default/files/2020-12/CVPR_2021_Home%20Page.jpg')">
    <div class="header-content" style="color:white; background-color: rgba(0, 0, 0, 0.4);">
        <div class="header-content-inner">
        	
            <h1>Second International Workshop on Large Scale Holistic Video Understanding</h1>
            <hr>
            <h2">In Conjunction with CVPR 2021,</h2>
            <!--<a href="#about" class="btn btn-primary btn-xl page-scroll">Find Out More</a>-->
            <a href="" target="_blank">
            	<img src="" class="img-logo" alt="">
            </a>
        </div>
    </div>
</header>

<section class="text-dark" id="about">
    <div class="container">
    	<div class="row" style="padding-bottom: 50px">
    		<div class="col-md-6">
    			<p>Holistic Video Understanding is a joint project of the KU Leuven, University of Bonn, KIT, ETH, and the <a href="../index.html#team" target="_blank">HVU team</a>.</p>
    		</div>
    		<div class="col-md-6">
    			<div class="row">
		    		<div class="col-md-4 text-center">
		    			<img src="../img/portfolio/KULeuven.png" class="img-logo" alt="">
		    		</div>
		    		<div class="col-md-4 text-center">
		    			<img src="../img/portfolio/Bonn.png" class="img-logo" alt="">
		    		</div>
		    		<div class="col-md-4 text-center">
		    			<img src="../img/portfolio/KIT.svg" class="img-logo" alt="">
		    		</div>
		    	</div>
		    	<div class="row">
		    		<div class="col-md-4 text-center">
		    			<img src="../img/portfolio/ETH.png" class="img-logo" alt="">
		    		</div>
		    	</div>
    		</div>
    	</div>
        <div class="row">
            <!--<div class="col-lg-8 col-lg-offset-2 text-center">-->
            <div class="col-md-6 text-center">
                <h2 class="section-heading">ABOUT THE WORKSHOP</h2>
                <hr class="light">
                <p class="text-dark" align="justify">In the last years, we have seen tremendous progress in the capabilities of computer systems to classify video clips taken from the Internet or to analyze human actions in videos. There are lots of works in video recognition field focusing on specific video understanding tasks, such as action recognition, scene understanding, etc. There have been great achievements in such tasks, however, there has not been enough attention toward the holistic video understanding task as a problem to be tackled. Current systems are expert in some specific fields of the general video understanding problem. However, for real-world applications, such as, analyzing multiple concepts of a video for video search engines and media monitoring systems or providing an appropriate definition of the surrounding environment of a humanoid robot, a combination of current state-of-the-art methods should be used. Therefore, in this workshop, we intend to introduce the holistic video understanding as a new challenge for the video understanding efforts. This challenge focuses on the recognition of scenes, objects, actions, attributes, and events in the real world user-generated videos. To be able to address such tasks, we also introduce our new dataset named Holistic Video Understanding~(HVU dataset) that is organized hierarchically in a semantic taxonomy of holistic video understanding. Almost all of the real-world conditioned video datasets are targeting human action or sport recognition. So our new dataset can help the vision community and bring more attention to bring more interesting solutions for holistic video understanding. The workshop is tailored to bringing together ideas around multi-label and multi-task recognition of different semantic concepts in the real world videos. And the research efforts can be tried on our new dataset.</p>
                <!--<a href="#" class="btn btn-default btn-xl">Coming Soon</a>-->
            </div>
            <div class="col-md-6 text-center">
                <h2 class="section-heading">WHAT IS OUR GOAL?</h2>
                <hr class="light">
                <p class="text-dark" align="justify">The main objective of the workshop is to establish a video benchmark integrating joint recognition of all the semantic concepts,  as a single class label per task is often not sufficient to describe the holistic content of a video. The planned panel discussion with world’s leading experts on this problem will be a fruitful input and source of ideas for all participants. Further, we invite the community to help to extend the HVU dataset that will spur research in video understanding as a comprehensive, multi-faceted problem. We as organizers expect to receive valuable feedback from users and from the community on how to improve the benchmark. <!--A few potential issues for the discussion are:--></p>
                <h2 class="section-heading">TOPICS</h2>
                <hr class="light">
                <ul class="text-dark" style="font-size: 20px" align="left">
                <li>Large scale video understanding</li>
                <li>Multi-Modal learning from videos</li>
                <li>Multi concept recognition from videos</li>
				<li>Multi task deep neural networks for videos</li>
				<li>Learning holistic representation from videos</li>
				<li>Weakly supervised learning from web videos</li>
				<li>Object, scene and event recognition from videos</li>
				<li>Unsupervised video visual representation learning</li>
				<li>Unsupervised and self-­supervised learning with videos</li>
                </ul>
                <!--<a href="#" class="btn btn-default btn-xl">Coming Soon</a>-->
            </div>
        </div>
    </div>
</section>

<section class="bg-gray" id="speakers">
    
      <div class="container">
        
        <div class="row">
            <div class="col-lg-12 text-center">
                <h2 class="section-heading">SPEAKERS</h2>
                <hr class="primary">
            </div>
        </div>
        
        
        <div class="row no-gutter">
            <div class="col-md-4" style="align-content: right;" id="S1">
                <a href="https://thoth.inrialpes.fr/~schmid/" target="_blank" class="portfolio-box">
                    <img src="img/portfolio/CordeliaSchmid.png" class="img-responsive" alt="">
                    <br><p>Cordelia Schmid</p>
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-category text-faded">
                                Cordelia Schmid
                            </div>
                            <div class="project-name">
                                Research Director<br>INRIA/Google Research
                            </div>
                        </div>
                    </div>
                </a>
            </div>
            <div class="col-md-4" id="S2">
                <a href="https://www.linkedin.com/in/jo%C3%A3o-carreira-56238a7/?originalSubdomain=uk" target="_blank" class="portfolio-box">
                    <img src="img/portfolio/JoaoCarreira.png" class="img-responsive" alt="">
                    <br><p>Joao Carreira</p>
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-category text-faded">
                                Joao Carreira
                            </div>
                            <div class="project-name">
                                Staff Research Scientist at Google DeepMind
                            </div>
                        </div>
                    </div>
                </a>
            </div>
            <div class="col-md-4" style="align-content: right;" id="S8">
                <a href="http://www.cs.columbia.edu/~vondrick/" target="_blank" class="portfolio-box">
                    <img src="img/portfolio/CarlVondrick.png" class="img-responsive" alt="">
                    <br><p>Carl Vondrick</p>
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-category text-faded">
                                Carl Vondrick
                            </div>
                            <div class="project-name">
                                 Assistant Professor, Columbia University
                            </div>
                        </div>
                    </div>
                </a>
            </div>
            <div class="col-md-4" id="S4">
                    <a href="http://people.cs.bris.ac.uk/~damen/" target="_blank" class="portfolio-box">
                        <img src="img/portfolio/DimaDamen.png" class="img-responsive" alt="">
                        <br><p>Dima Damen</p>
                        <div class="portfolio-box-caption">
                            <div class="portfolio-box-caption-content">
                                <div class="project-category text-faded">
                                    Dima Damen
                                </div>
                                <div class="project-name">
                                    Associate Professor at the Department of Computer Science, Visual Information Laboratory, University of Bristol
                                </div>
                            </div>
                        </div>
                    </a>
            </div>
            <div class="col-md-4" id="S4">
                    <a href="https://www.cs.utoronto.ca/~fidler/" target="_blank" class="portfolio-box">
                        <img src="img/portfolio/SanjaFidler.png" class="img-responsive" alt="">
                        <br><p>Sanja Fidler</p>
                        <div class="portfolio-box-caption">
                            <div class="portfolio-box-caption-content">
                                <div class="project-category text-faded">
                                    Sanja Fidler
                                </div>
                                <div class="project-name">
                                    Associate Professor, University of Toronto <br> Director of AI, NVIDIA
                                </div>
                            </div>
                        </div>
                    </a>
            </div>
            <div class="col-md-4" id="S4">
                    <a href="https://www.cs.utexas.edu/users/grauman/" target="_blank" class="portfolio-box">
                        <img src="img/portfolio/KristenGrauman.png" class="img-responsive" alt="">
                        <br><p>Kristen Grauman</p>
                        <div class="portfolio-box-caption">
                            <div class="portfolio-box-caption-content">
                                <div class="project-category text-faded">
                                    Kristen Grauman
                                </div>
                                <div class="project-name">
                                    Professor in the Department of Computer Science at the University of Texas at Austin <br> Head of the UT-Austin Computer Vision Group
                                </div>
                            </div>
                        </div>
                    </a>
            </div>
        </div>
    
        </div>
    </div>
</section>
<!--
<section class="" id="awards">
    <div class="container">
        
        <div class="row">
            <div class="col-lg-12 text-center">

                <h2 class="section-heading">AWARDS</h2>
                <i class="fas fa-award fa-4x wow bounceIn" data-wow-delay=".1s"></i>
                <hr class="primary">
            </div>
        </div>
        <div class="row">
            <div class="col-md-6 text-center" style="display: flex; justify-content: center; font-size: 18px">
                <div>
                    <h3 class="section-heading">Best Paper Award</h3>
                    <hr class="primary">
                    <div style="justify-content: left;">
                        <b >TBA</b>
                    </div>
                </div>
            </div>
            <div class="col-md-6 text-center" style="display: flex; justify-content: center; font-size: 18px">
                <div>
                    <h3 class="section-heading">Best Poster Award</h3>
                    <hr class="primary">
                    <b>TBA</b>
                </div>
            </div>
        </div>
        <div class="row">
            <div class="col-lg-12 text-center" style="display: flex; justify-content: center; font-size: 16px; padding-top: 40px">
                TBA
            </div>
        </div>
    </div>
    
</section>-->

<section class="" id="program">
    
      <div class="container">
        
        <div class="row">
            <div class="col-lg-12 text-center">
                <h2 class="section-heading">WORKSHOP PROGRAM</h2>
                <hr class="primary">
                <div class="text-dark" style="font-size: 19px">
                    TBA <br><b></b></a><br>
                </div>
            </div>
        </div>
	</div>
</section>
        <!--
        <div class="row no-gutter">
            <div class="col-lg col-lg-offset-0  align-center" style="display: flex; justify-content: center; font-size: 18px">
                <table>
                  <tbody>
                    

                    <tr>
                        <td style="min-width: 70px"><b>Time</b></td>
                        <td colspan="0" style="min-width: 170px"><b>Description</b></td>
                        <td colspan="0" style=""><b>Speaker/Paper ID</b></td>
                    </tr>
                    <tr>
                        <td>13:30</td>
                        <td>Opening remark</td>
                        <td></td>
                    </tr>
                    <tr>
                        <td>13:40</td>
                        <td>Invited Speaker 1: </td>
                        <td colspan="0"><a class="page-scroll" href="#S2">Juan Carlos Niebles</a></td>
                    </tr>
                    <tr>
                        <td>14:10</td>
                        <td>Invited Speaker 2:</td>
                        <td><a class="page-scroll" href="#S1">Raquel Urtasun</a></td>
                    </tr>
                    <tr>
                        <td>14:40</td>
                        <td>Coffee and Posters</td>
                        <td></td>
                    </tr>
                    <tr>
                        <td>15:25</td>
                        <td>4 Oral Talks</td>
                        <td colspan="2"><a class="page-scroll" href="#orals">23, 16, 8, 22</a></td>
                    </tr>
                    <tr>
                        <td>16:15</td>
                        <td>Invited Speaker 3:</td>
                        <td colspan="2"><a class="page-scroll" href="#S3">Du Tran</a></td>
                    </tr>
                    <tr>
                        <td>16:45</td>
                        <td>Invited Speaker 4:</td>
                        <td><a class="page-scroll" href="#S4">David Ross</a></td>
                    </tr>
                    <tr>
                        <td>17:15</td>
                        <td>3 Oral Talks: </td>
                        <td><a class="page-scroll" href="#orals">7, 4, 9</a></td>
                    </tr>
                    <tr>
                        <td>17:50</td>
                        <td>Conclusion and Awards</td>
                        <td></td>
                    </tr>
                    </tbody>
                </table>
            </div>
        </div>
        <div class="row" id="orals">
           <div class="col-lg col-lg-offset-0 text-center" style="padding-left: 15px; padding-right: 15px; padding-top: 30px">
                <h2 class="section-heading">Oral Papers</h2>
                <hr class="primary">
                <p class="text-dark" align="justify" style="font-size: 19px">
                    4. <b>Recurrent Convolutions for Causal 3D CNNs</b>; Gurkirt Singh, Fabio Cuzzolin<br>
                    7. <b>Video Representation Learning by Dense Predictive Coding</b>; Tengda Han, Weidi Xie, Andrew Zisserman<br>
                    8. <b>Towards Segmenting Anything That Moves</b>; Achal D Dave, Pavel Tokmakov, Deva Ramanan <br>
                    9. <b>Video-Text Compliance: Activity Verification Based on Natural Language Instructions</b>; Mayoore Jaiswal et al.<br>
                    16. <b>HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips</b>; Antoine Miech et al.<br>
                    22. <b>Deep Multimodal Feature Encoding for Video Ordering</b>; Vivek Sharma, Makarand Tapaswi, Rainer Stiefelhagen <br>
                    23. <b>CATER: A diagnostic dataset for Compositional Actions and TEmporal Reasoning</b>; Rohit Girdhar, Deva Ramanan<br>
                </p>
            </div> 
        </div>

	<div class="row">
           <div class="col-lg col-lg-offset-0 text-center" style="padding-left: 15px; padding-right: 15px; padding-top: 30px" >
                <h2 class="section-heading">Poster Session</h2>
                <hr class="primary">
                <p class="text-dark" align="justify" style="font-size: 15px">
		   <b>-Recurrent Convolutions for Causal 3D CNNs</b>; Gurkirt Singh, Fabio Cuzzolin<br>
		   <b>-Level Selector Network for Optimizing Accuracy-Specificity Trade-offs</b>; Ahsan Iqbal, Jürgen Gall<br>
                  <b>-End-to-End Video Captioning</b>; Silvio Olivastri, Gurkirt Singh, Fabio Cuzzolin<br>
		<b>-Video Representation Learning by Dense Predictive Coding</b>; Tengda Han, Weidi Xie, Andrew Zisserman<br>
		<b>-Towards Segmenting Anything That Moves</b>; Achal D Dave, Pavel Tokmakov, Deva Ramanan<br>
		<b>-Video-Text Compliance: Activity Verification Based on Natural Language Instructions</b>; Mayoore Jaiswal, Frank Liu, Anupama Jagannathan, Anne Gattiker, Inseok Hwang, Jinho Lee, Matt Tong, Sahil Dureja, Soham Shah, Peter Hofstee, Valerie Chen, Suvadip Paul, Rogerio Feris<br>
		<b>-Interpretable Spatio-temporal Attention for Video Action Recognition</b>; Lili Meng<br>
		<b>-Markov Decision Process for Video Generation</b>; Vladyslav Yushchenko, Nikita Araslanov, Stefan Roth<br>
		<b>-Next-flow: Hybrid multi-tasking with next-frame prediction to boost optical-flow estimation in the wild</b>; Nima Sedaghat, Mohammadreza Zolfaghari<br>
		<b>-Use What You Have: Video retrieval using representations from collaborative experts</b>; Yang Liu, Samuel Albanie, Arsha Nagrani, Andrew Zisserman<br>
		<b>-HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips</b>; Antoine Miech, Dimitri Zhukov, Jean-Baptiste Alayrac, Makarand Tapaswi, Ivan Laptev, Josef Sivic<br>
		<b>-Coupled Recurrent Network (CRN)</b>; Lin Sun<br>
		<b>-Deep Multimodal Feature Encoding for Video Ordering</b>; Vivek Sharma, Makarand Tapaswi, Rainer Stiefelhagen<br>
		<b>-CATER: A diagnostic dataset for Compositional Actions and TEmporal Reasoning</b>; Rohit Girdhar, Deva Ramanan<br>
		<b>-Class-Agnostic Object Tracking with a Focus on the Object</b>; Achal D Dave, Pavel Tokmakov, Cordelia Schmid, Deva Ramanan<br>
		<b>-Skip-Clip: Self-Supervised Spatiotemporal Representation Learning by Future Clip Order Ranking</b>; Alaaeldin M El-Nouby, Shuangfei Zhai, Graham Taylor, Josh Susskind<br>

                </p>
                
            </div> 
        </div>
							      
    </div>
-->
</section>

<section class="bg-gray" id="call-for-paper">
	<div class="container" >
		<div class="row">
            <!--<div class="col-lg-8 col-lg-offset-2 text-center">-->
            <div class="col-lg col-lg-offset-0 text-center" style="padding-left: 15px; padding-right: 15px" >
                <h2 class="section-heading">CALL FOR PAPER</h2>
                <hr class="primary">
                <p class="text-dark" align="justify">Prospective authors will be invited to submit a regular paper of previously unpublished work (CVPR paper format) or an extended abstract of a published work. The review process will be double blind. All the submissions will be peer-reviewed by the international program committee. Accepted papers will be presented as posters or contributed talks and will be considered non-archival and published via the Open Access versions, provided by the Computer Vision Foundation. Accepted extended abstracts will be presented at the poster session.</p>
                <!--<a href="#" class="btn btn-default btn-xl">Coming Soon</a>-->
            </div>
        </div>
        
        <div class="row align-center">
        	<!--
        	<div class="col-md-3 text-center">
        		<div class="service-box">
        			<a href="https://github.com/holistic-video-understanding/HVU-Dataset" target="_blank">
	        			<i class="fas fa-flag fa-4x wow bounceIn" data-wow-delay=".1s"></i>
	        			<h4>DataSet Released</h4>
	        			<h4>May 31</h4>
        			</a>
        		</div>
        	</div>-->
        	<div class="col-md-3 text-center">
        		<div class="service-box">
        			<a class="page-scroll" href="#submission">
	        			<i class="fas fa-paper-plane fa-4x wow bounceIn" data-wow-delay=".1s"></i>
	        			<h4>Paper Submission Starts*</h4>
	        			<h4>February 20</h4>
	        		</a>
        		</div>
        	</div>
        	<div class="col-md-3 text-center">
        		<div class="service-box">
        			<a href="https://cmt3.research.microsoft.com/HVU2021" target="_blank">
	        			<i class="fas fa-flag fa-4x wow bounceIn" data-wow-delay=".1s"></i>
	        			<h4>Paper Submission Deadline</h4>
	        			<h4>TBA</h4>
        			</a>
        		</div>
        	</div>
        	<div class="col-md-3 text-center">
        		<div class="service-box">
                    <a href="https://cmt3.research.microsoft.com/HVU2021" target="_blank">
        			 <i class="fas fa-check fa-4x wow bounceIn" data-wow-delay=".1s"></i>
        			 <h4>Notification of Acceptance</h4>
        			 <h4>TBA</h4>
                    </a>
        		</div>
        	</div>
        	<div class="col-md-3 text-center">
        		<div class="service-box">
                    <a href="https://cmt3.research.microsoft.com/HVU2019" target="_blank">
        			 <i class="fas fa-camera fa-4x wow bounceIn" data-wow-delay=".1s"></i>
        			 <h4>Camera Ready Submission</h4>
        			 <h4>TBA</h4>
                    </a>
        		</div>
        	</div>
        </div>
        <div class="row align-center">
        
        	<div class="col-lg-8 col-lg-offset-2 text-center">
            <div class="col-lg col-lg-offset-0 text-center" style="padding-left: 15px; padding-right: 15px; padding-top: 35px" >
        		<div class="service-box">
        			<i class="fas fa-users fa-4x wow bounceIn" data-wow-delay=".1s"></i>
        			<h4>Workshop</h4>
        			<h4>TBA</h4>
        		</div>
        	</div>
        	</div>
        </div>
        
        <!--</div>-->

        <!--
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 text-center">
                s
            <div class="col-lg col-lg-offset-0 text-center" style="padding-left: 15px; padding-right: 15px; padding-top: 35px" >
                <h2 class="section-heading"></h2>
                <i class="fas fa-award fa-4x wow bounceIn" data-wow-delay=".1s"></i>
                <h4 class="text-dark" align="justify-center">Best paper and best poster will receive prizes</h4>
            	
            </div>
        </div>
    -	-->
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 text-center">
            <div class="col-lg col-lg-offset-0 text-center" style="padding-left: 15px; padding-right: 15px; padding-top: 35px" >
                <h2 class="section-heading"></h2>
                <a href="https://github.com/holistic-video-understanding/HVU-Dataset" target="_blank">
                	<i class="fas fa-database fa-4x wow bounceIn" data-wow-delay=".1s"></i>
                	<h4 align="justify-center">Get the DataSet!</h4>
			<h4 class="text-dark" align="justify-center">The authors are encouraged to use our dataset in their submission, but it is not mandatory.</h4>
						  
            	</a>
            </div>
        	</div>
        </div>
        
        <div class="row">
            <div class="col-lg col-lg-offset-0 text-center" style="padding-left: 15px; padding-right: 15px; padding-top: 35px" id="submission" >
                <h2 class="section-heading">Submission</h2>
                <hr class="primary">
                <p class="text-dark" align="justify">
                	*You can submit papers in two different formats:
                	<ol class="text-dark" align="justify">
	                	<li>We will accept papers that have not been published elsewhere or have been recently published elsewhere including CVPR 2021. Accepted papers will appear in CVPR proceedings. For submissions of papers, we will follow the <b>Double Blind</b> review process, in that authors do not know the names of the reviewers of their papers, and reviewers do not know the names of the authors. The authors must follow the CVPR 2021 submission policy. Papers are limited to eight pages, including figures and tables, in the CVPR style. Additional pages containing only cited references are allowed. Please refer to the CVPR 2021 website for more information. Papers that are not properly anonymized, or do not use the template, or have more than eight pages (excluding references) will be rejected without review. The deadline for paper submission is <b>TBA</b>. Notification to the authors by <b>TBA</b>. The accepted papers must follow the CVPR 2021 camera-ready format as per the instructions are given here but limit your paper to 4-8 pages excluding references.</li>
	                	
						<li>For submissions of papers that have been published or accepted for publication in a recent venue, we will follow the <b>Single Blind</b> review process, in that authors do not know the names of the reviewers of their papers, but reviewers do know the names of the authors. Authors MUST indicate, in the footnote section on the first page of their submission, which venue their papers have been published or will be published. For example, if the paper will appear at CVPR 2021, the submission should include a footnote on the first page showing "To appear at 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition". Therefore, the deadline for paper submission is <b>TBA</b>. Notification to the authors by <b>TBA</b>.</li>
						
						<!--<li>Authors can also submit a maximum of 4-8 pages (excluding references) which will be peer-reviewed. We will follow the <b>Single Blind</b> review process. However, they will not be included in the proceedings. Accepted papers will be presented as posters or contributed talks. Authors of accepted papers will be asked to post their submissions on arXiv. The workshop website will provide links to the accepted papers on arXiv. Accepted papers will be considered non-archival, and may be submitted elsewhere (modified or not). Therefore, the deadline for paper submission is <b>TBA</b>. Notification to the authors by <b>TBA</b>.</li>-->
					</ol>
					All papers must be formatted using the CVPR template style, which can be obtained at <a href="http://cvpr2021.thecvf.com/sites/default/files/2020-09/cvpr2021AuthorKit_2.zip">CVPR style</a>.</p>
                <a href="https://cmt3.research.microsoft.com/HVU2021" target="_blank" class="btn btn-default btn-xl">Submit Your Work</a>
            </div>
        </div> 
	</div>
</section>


<section class="" id="pc">
    <div class="container">
    	<div class="row text-center">
    		<h2 class="section-heading">Program Commitee</h2>
    		<hr class="primary">
    	</div>
        <div class="row">
            <!--<div class="col-lg-8 col-lg-offset-2 text-center">-->
            <div class="col-md-6 text-center">
                <ul class="text-dark" style="font-size: 20px" align="left">
                TBA
                <!--
                <li>Cees Snoek (UvA)</li>
                <li>Ivan Laptev (INRIA)</li>
                <li>Chen Huang (Apple)</li>
                <li>Mubarak Shah (UCF)</li>
				<li>Efstratios Gavves (UvA)</li>
                <li>Noureldien Hussein (UvA)</li>
                <li>Suman Shah (ETH Zürich)</li>
                <li>Jan van Gemert (TU Delft)</li>
                <li>Hamed Pirsiavash (UMBC)</li>
				<li>Silvia-Laura Pintea (TU Delft)</li>
				<li>Du Tran (Facebook Research)</li>
				<li>Dima Damen (University of Bristol)</li>
				<li>Rohit Girdhar (Facebook Research)</li>
				<li>Jack Valmadre (University of Oxford)</li>
				<li>Hilde Kuehne (MIT-IBM Watson Lab)</li>
				<li>Hakan Bilen (University of Edinburgh)</li>
				<li>Alexander Richard (University of Bonn)</li>
                <li>Jakub Tomczak (Qualcomm AI Research)</li>
				<li>Christoph Feichtenhofer (Facebook Research)</li>
				-->
				
                </ul>
                <!--<a href="#" class="btn btn-default btn-xl">Coming Soon</a>-->
            </div>
            <div class="col-md-6 text-center">
                <ul class="text-dark" style="font-size: 20px" align="left">
                TBA
                <!--
				<li>Saquib Sarfraz (KIT)</li>
                <li>Josh Susskind (Apple)</li>
                <li>Mohammad Sabokro (IPM)</li>
				<li>Makarand Tapaswi (INRIA)</li>
				<li>Andrew Owens (UC Berkley)</li>
				<li>Ross Goroshin (Google Brain)</li>
				<li>Tinne Tuytelaars (KU Leuven)</li>
				<li>Miguel Angel Bautista (Apple)</li>
				<li>Chen Sun (Google Research)</li>
				<li>David Ross (Google Research)</li>
				<li>Limin Wang (Nanjing University)</li>
				<li>Yale Song (Microsoft Cloud & AI)</li>
				<li>Matt Feiszli (Facebook Research)</li>
				<li>Joao Carreira (Google Deepmind)</li>
				<li>Philippe Weinzaepfel (NAVER Labs)</li>
                <li>Hilde Kuehne (MIT-IBM Watson Lab)</li>
				<li>Sourish Chaudhuri (Google Research)</li>
				<li>Basura Fernando (A*STAR Singapore)</li>
				<li>Angela Yao (National University of Singapore)</li>
                </ul>
            -->
                <!--<a href="#" class="btn btn-default btn-xl">Coming Soon</a>-->
            </div>
        </div>
    </div>
</section>

<section class="bg-gray" id="organizers">
      <div class="container text-center">
      <div class="row">
          <div class="call-to-action">
              <h2>ORGANIZERS</h2>
              <hr class="primary">
          </div>
      </div>
      		<div class="row no-gutter">
      			<div class="col-md-4" >
	                <a href="http://mohsenfayyaz89.github.io" target="_blank" class="portfolio-box">
	                    <img src="img/portfolio/MohsenFayyaz.png" class="img-responsive" alt="">
			    		<br><p>Mohsen Fayyaz</p>
	                    <div class="portfolio-box-caption">
	                        <div class="portfolio-box-caption-content">
	                            <div class="project-category text-faded">
	                                Mohsen Fayyaz
	                            </div>
	                            <div class="project-name">
	                                PhD candidate at the University of Bonn
	                            </div>
	                        </div>
	                    </div>
	                </a>
	            </div>
                <div class="col-md-4">
		                <a href="http://vivoutlaw.github.io/" target="_blank" class="portfolio-box">
		                    <img src="img/portfolio/VivekSharma.png" class="img-responsive" alt="">
		                    <br><p>Vivek Sharma</p>
		                    <div class="portfolio-box-caption">
		                        <div class="portfolio-box-caption-content">
		                            <div class="project-category text-faded">
		                                Vivek Sharma
		                            </div>
		                            <div class="project-name">
		                                
		                            </div>
		                        </div>
		                    </div>
		                </a>
		        </div>
	            
	            <div class="col-md-4">
	                <a href="https://www.esat.kuleuven.be/psi/members/00098021" target="_blank" class="portfolio-box">
	                    <img src="img/portfolio/AliDiba.png" class="img-responsive" alt="">
	                    <br><p>Ali Diba</p>
	                    <div class="portfolio-box-caption">
	                        <div class="portfolio-box-caption-content">
	                            <div class="project-category text-faded">
	                                Ali Diba
	                            </div>
	                            <div class="project-name">
	                                PhD candidate at the KU-Leuven University
	                            </div>
	                        </div>
	                    </div>
	                </a>
	            </div>
		        
        	</div>
        
        	
        <div class="row no-gutter">
            <div class="col-md-4">
                <a href="https://www.vision.ee.ethz.ch/en/members/get_member.cgi?id=1" target="_blank" class="portfolio-box">
                    <img src="img/portfolio/LucVanGool.png" class="img-responsive" alt="">
		    		<br><p>Luc Van Gool</p>
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-category text-faded">
                                Luc Van Gool
                            </div>
                            <div class="project-name">
                                Full Professor for Computer Vision at both the KULeuven  and  the  ETH  Zurich
                            </div>
                        </div>
                    </div>
                </a>
            </div>
            <div class="col-md-4">
                <a href="http://gall.cv-uni-bonn.de/" target="_blank" class="portfolio-box">
                    <img src="img/portfolio/JuergenGall.png" class="img-responsive" alt="">
                    <br><p>Juergen Gall</p>
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-category text-faded">
                                Juergen Gall
                            </div>
                            <div class="project-name">
                                Full Professor and Head of the Computer Vision Group at the University of Bonn
                            </div>
                        </div>
                    </div>
                </a>
            </div>
            <div class="col-md-4" >
                    <a href="https://web.stanford.edu/~eadeli/" target="_blank" class="portfolio-box">
                        <img src="img/portfolio/EhsanAdeli.png" class="img-responsive" alt="">
                        <br><p>Ehsan Adeli</p>
                        <div class="portfolio-box-caption">
                            <div class="portfolio-box-caption-content">
                                <div class="project-category text-faded">
                                    Ehsan Adeli
                                </div>
                                <div class="project-name">
                                    Faculty at Computational Neurosience Lab and affiliated with Stanford AI Lab and Stanford Vision Lab
                                </div>
                            </div>
                        </div>
                    </a>
            </div>
            <div class="col-md-4">
                    <a href="http://www.cs.toronto.edu/~dross/" target="_blank" class="portfolio-box">
                        <img src="img/portfolio/DavidRoss.png" class="img-responsive" alt="">
                        <br><p>David Ross</p>
                        <div class="portfolio-box-caption">
                            <div class="portfolio-box-caption-content">
                                <div class="project-category text-faded">
                                    David Ross
                                </div>
                                <div class="project-name">
                                    Head of the Visual Dynamics research group, Google AI Perception
                                </div>
                            </div>
                        </div>
                    </a>
            </div>
		   <div class="col-md-4">
	                <a href="https://cvhci.anthropomatik.kit.edu/people_596.php" target="_blank" class="portfolio-box">
	                    <img src="img/portfolio/RainerStiefelhagen.png" class="img-responsive" alt="">
	                    <br><p>Rainer Stiefelhagen</p>
	                    <div class="portfolio-box-caption">
	                        <div class="portfolio-box-caption-content">
	                            <div class="project-category text-faded">
	                                Rainer Stiefelhagen
	                            </div>
	                            <div class="project-name">
	                                Full Professor at the Karlsruhe Institute of Technology (KIT)
	                            </div>
	                        </div>
	                    </div>
	                </a>
	        </div>
	        <div class="col-md-4">
	                <a href="https://research.fb.com/people/paluri-manohar/" target="_blank" class="portfolio-box">
	                    <img src="img/portfolio/ManoharPaluri.png" class="img-responsive" alt="">
	                    <br><p>Manohar Paluri</p>
	                    <div class="portfolio-box-caption">
	                        <div class="portfolio-box-caption-content">
	                            <div class="project-category text-faded">
	                                Manohar Paluri
	                            </div>
	                            <div class="project-name">
	                                Director in Facebook AI Research
	                            </div>
	                        </div>
	                    </div>
	                </a>
	        </div>
        </div>
        
    </div>


</section>

<section class="" id="sponsors">
	<div class="container">
		<div class="row">
          <div class="col-lg-8 col-lg-offset-2 text-center">
              <h2>SPONSORS</h2>
              <hr class="primary">
          </div>
      	</div>
        TBA
        <!--
		<div class="row">
			<div class="col-md-4 col-lg-offset-0 text-center">
	            
	                <img src="img/portfolio/FacebookAI.png" class="img-responsive" alt="" style="padding-top: 20px">
	                <p style="padding-top: 10px"><br>Facebook AI Research</p>
	            
	        </div>
	        <div class="col-md-4 col-lg-offset-0 text-center">
                
                    <img src="img/portfolio/Apple_Logo_Black.png" class="img-responsive" alt="" style="width: 17%; height: 17%; padding-top: 0px">
                    <p style="padding-top: 25px">Apple</p>
                
            </div>
            <div class="col-md-4 text-center">
	            
		            <img src="img/portfolio/sensifai.svg" class="img-responsive" alt="" style="padding-top: 25px">
		            <p style="padding-top: 10px"><br>Sensifai</p>
	            
	        </div>
            
	        
	        <div class="col-md-3 text-center">
	            <a href="http://www.apple.com" target="_blank" >
	            	<i class="fab fa-apple fa-4x" style="color: black"></i>
		            <img src="img/portfolio/apple.png" class="img-responsive" alt="" style="padding-top: 0px">
		            <p><br>Apple</p>
	            </a>
	        </div>
	        <div class="col-md-3 text-center">
	            <a href="https://research.samsung.com/aicenter" target="_blank">
		            <img src="img/portfolio/samsung.png" class="img-responsive" alt="" style="padding-top: 10px">
		            <p style="padding-top: 2px"><br>Samsung</p>
	            </a>
	        </div>
	    	-->
		</div>
	</div>
</section>

<section class="bg-gray" id="contact">
    <div class="container">
        <div class="row">

            <div class="col-lg-8 col-lg-offset-2 text-center">
                <h2 class="section-heading">CONTACT</h2>
                <hr class="primary">
                
            </div>
        </div>
        <div class="row">
	        <div class="col-lg-2 col-lg-offset-2 text-center">
	            <a href="https://twitter.com/LSHVU" target="_blank">
	                <i class="fab fa-twitter fa-3x wow bounceIn" data-wow-delay=".1s"></i>
	                <p>@LSHVU</p>
	            </a>
	        </div>
	        <div class="col-lg-2 col-lg-offset-1 text-center">
	            <a href="mailto:fayyaz@iai.uni-bonn.de">
	                <i class="fas fa-envelope fa-3x wow bounceIn" data-wow-delay=".1s"></i>
                	<p>fayyaz@iai.uni-bonn.de</p>
	            </a>
	        </div>
	        <div class="col-lg-2 col-lg-offset-1 text-center">
	            <a href="https://github.com/holistic-video-understanding" target="_blank">
	            <i class="fab fa-github fa-3x wow bounceIn" data-wow-delay=".1s"></i>
	                <p>holistic-video-understanding</p>
	            </a>
	        </div>

    	</div>
    </div>
</section>
  <!-- jQuery -->
<script src="../js/jquery.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="../js/bootstrap.min.js"></script>

<!-- Plugin JavaScript -->
<script src="../js/jquery.easing.min.js"></script>
<script src="../js/jquery.fittext.js"></script>
<script src="../js/wow.min.js"></script>

<!-- Custom Theme JavaScript -->
<script src="../js/creative.js"></script>

</body>

</html>
